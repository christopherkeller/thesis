%!TEX root=index.tex
\newacronym{cse}{CSE}{Certified Solution Executive}
\section{Executive Summary}
\textsc{CSC's} ClimatEdge\texttrademark{}\index{ClimatEdge} offering is focused on providing predictive climate analytics using public government data sets. By using various algorithms, both proprietary and public, \textsc{CSC} plans to offer its customers a distinct advantage by allowing strategic business decisions to be made based on climate and extreme weather predictions. Planned offerings for the general insurance industry include the probability of tornado, hail, or flood occurrences in a particular geographical grid cell, as well as hail occurrence.\\

This paper focuses on contrasting the tornado and flood offerings with respect to the attributes associated with big data: velocity, volume, and variety. The hail offering is similar enough in variety to tornado and in volume to flood, that analyzing it separately does not add further insights or value. Tornado prediction involves running a published algorithm against a relatively small amount of structured data on modest hardware. In short, it does not meet the criteria for big data. Flood prediction, on the other hand, requires substantially larger and more diverse data such as newspaper reports, hydrologic data from stream gauges, and parcel information in addition to rainfall and other climate data. In contrast to tornado, it does meet several criteria for big data. The minimal platform capable of delivering the tornado probabilities is not capable of offering flood probabilities. Without an investment in big data technology and expertise, the range of ClimatEdge\index{ClimatEdge} offerings will be limited.\\

Next, a reference framework implementation is presented that will allow tornado, flood, and future ClimatEdge\index{ClimatEdge} offerings to scale in processing both large and complex data sets, thus enabling a wider variety of business cases to be developed into offerings. The most important framework characteristic is flexibility in technologies and a loose coupling between the layers. There does not exist a single application or technology capable of addressing every offering scenario, so a collection of specific technologies that can be integrated together is presented. As technologies evolve, the goal is to be able to replace any one piece of technology without overly affecting other layers.\\

Finally, three future research ideas around the processing of large data sets is presented. The first relies on a data owner enabling programatic access, but not necessarily analysis, to the data.  The second option focuses on the possible legal implications of results derived from cloning any data sets for local storage. Finally, an approach based on moving the analysis to the provider data center is explored. Each approach has both advantages and disadvantages and is suitable for further research within \textsc{CSC} or as a follow on \gls{cse} thesis.
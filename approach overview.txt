
Proposed Thesis

Quantitative Prediction Adds Significant Enhancement to ClimatEdge™

Background

Currently ClimatEdge, based largely on qualitative analysis, is performed by a subject matter expert using publicly available information about trends in climate conditions and simple analysis using selected public data sets, to provide commentary and analysis about future weather and climate relative to the commodities market. These data sets do not necessarily conform to widely accepted definitions of big data: velocity, volume, and variety. Therefore, it’s difficult to conclusively prove that applying “big data” to ClimatEdge adds any significant business value.

However, if ClimatEdge moved in a more quantitative direction, via larger & more diverse data sets, applying big data technologies to produce probabilistic predictions of weather and climate conditions is of relevance to a variety of markets.

Three use case scenarios have been identified for the risk industry:

* tornado & hail damage
* flood prediction
* commodities trading

By focusing on the probability (using big data on past data sets) of future climate change we can use the following equation: Risk = Impact * Probability to give the risk industry a significant business advantage. This is something that the current implementation of ClimatEdge can not address.

Approach

I'll start out by building a multi-part scenario focusing on tornado & hail damage:

* the first part shows that CSC has access to vast amounts of data it's not currently pursing
* next is that we can create a framework capable of processing, storing, and analyzing this data
* the analytics/results of this processing is useful to the risk insurance industry

Next I focus on how this would actually work, by demonstrating that a small subset of data can offer valuable predictions. I think actually writing the code may be out of scope here, but hopefully I can get some help from the climate guys.

Next is other business cases that this approach would work for, i.e. flood, commodities, etc (and where they differ).

The final piece is where we do we go from here, i.e. how would we actually go about building this if we were proposing this. 

This should prove a quantitative substantiation of the thesis.


==============================================================================

ClimatEdge right now is using a small fraction of the publicly available data. Adding larger & more diverse data sets are critical for a couple of reasons:

* predictions, by nature, offer up a level of uncertainty for sure. However, we need to be able to use the historical data for trend analysis. For example, in consecutive years, following a la nina (or el nino) year, we find that soil moisture drops. Useful information for people in the commodities futures market. If we limit the amount of data, we [potentially] limit our accuracy.

* So, I agree that prediction is uncertain and in-exact, however it's not clear to me that it invalidates the hypothesis at all. 

Currently, ClimatEdge offers little predictive capabilities, because the current process has no method to analyze large amounts of historical data. That definitely limits our potential customers. I'm proposing we take the same qualitative analysis that we do now, only extend it out over larger amounts of data to make it more quantitative. 



